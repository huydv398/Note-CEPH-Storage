# Kiến trúc và các thành phần Ceph
1. [Kiến trúc CEPH]()
1. [CEPH STORAGE CLUSTER]()
1. [Lưu trữ dữ liệu]()
1. [SCALABILITY AND HIGH AVAILABILITY]()
    1. [Giới thiệu thuật toán CRUSH]()
    1. [CLUSTER MAP]()
    1. [HIGH AVAILABILITY MONITORS]()
    1. [HIGH AVAILABILITY AUTHENTICATION]()
    1. [SMART DAEMONS ENABLE HYPERSCALE]()
1. [DYNAMIC CLUSTER MANAGEMENT]()
    1. [POOLS]()
    1. [MAPPING PGS TO OSDS]()
    1. [CALCULATING PG IDS]()
    1. [PEERING AND SETS]()
    1. [REBALANCING]()
    1. [DATA CONSISTENCY]()
1. []()
1. []()
## Kiến trúc CEPH
Ceph cung cấp duy nhất object, block và file storage trong một hệ thống thống nhất. Ceph có độ tin cậy cao, dễ quản lý và miễn phí. Sức mạnh của Ceph có thể biến đổi cơ sở hạ tầng CNTT của công ty bạn và khả năng quản lý lượng lớn dữ liệu của bạn. 
![Imgur](https://i.imgur.com/6eLPwPy.png)</br>

## THE CEPH STORAGE CLUSTER
Ceph cung cấp Ceph Storage Cluster có khả năng mở rộng vô hạn dựa trên RADOS, bạn có thể đọc về điều này trong [RADOS - A Scalable, Reliable Storage Service for Petabyte-scale Storage Clusters](https://ceph.com/assets/pdfs/weil-rados-pdsw07.pdf).

Ceph Storage Cluster bao gồm nhiều loại daemon:

|**Ceph Monitor**|**Ceph OSD Daemon**|**Ceph Manager**|**Ceph Metadata Server**|
|-|-|-|-|
* **Ceph Monitor**: duy trì một bản sao chính của cluster map. Một cụm Ceph monitors đảm bảo tính khả dụng cao nếu daemon monitor bị lỗi. Storage cluster clients lấy bản sao của cluster map từ Ceph Monitor.
* **Ceph OSD Daemon**: kiểm tra trạng thái của chính nó và trạng thái của các OSD khác và báo cáo lại cho Monitor.
* **Ceph Manager**: hoạt động như một điểm cuối cho các mô-đun giám sát, điều phối và plug-in modules.
* **Ceph Metadata Server**: quản lý Metadata khi CephFS được sử dụng để cung cấp dịch vụ tệp.

**Storage cluster clients** và mỗi **Ceph OSD Daemon** sử dụng `thuật toán CRUSH` để tính toán hiệu quả thông tin về vị trí dữ liệu, thay vì phải phụ thuộc vào bảng tra cứu trung tâm. Các tính năng cấp cao của Ceph bao gồm giao diện gốc cho Ceph Storage Cluster thông qua thư viện `librados` và một số giao diện dịch vụ được xây dựng dựa trên thư viện `librados`.

## LƯU TRỮ DỮ LIỆU
**Ceph Storage Cluster** nhận dữ liệu từ *Ceph Clients* – cho dù dữ liệu đó đến qua *Ceph Block Device*, *Ceph Object Storage*, *Ceph File System* hoặc một triển khai tùy chỉnh mà bạn tạo bằng cách sử dụng thư viện `librados`- được lưu trữ dưới dạng các RADOS object. Mỗi objects được lưu trữ trên một Object Storage Device. Ceph OSD Daemon xử lý các hoạt động đọc, ghi và sao chép trên ổ lưu trữ. Với back end Filestore cũ hơn, mỗi RADOS object được lưu trữ dưới dạng tệp riêng biệt trên hệ thống tệp thông thường (thường là XFS). Với giao diện BlueStore mới và mặc định, các objects được lưu trữ theo kiểu cơ sở dữ liệu nguyên khối.

![Imgur](https://i.imgur.com/IPox3Kf.png)

Ceph OSD Daemon lưu trữ dữ liệu dưới dạng các objects trong một không gian tên phẳng (ví dụ: không có phân cấp thư mục). Một objects có số nhận dạng, dữ liệu nhị phân và siêu dữ liệu bao gồm một tập hợp các cặp tên/giá trị. Ngữ nghĩa hoàn toàn tùy thuộc vào Khách hàng Ceph. Ví dụ: CephFS sử dụng siêu dữ liệu để lưu trữ các thuộc tính tệp như chủ sở hữu tệp, ngày tạo, ngày sửa đổi lần cuối, v.v.

![Imgur](https://i.imgur.com/egNgkPv.png)

>ID objects là duy nhất trên toàn bộ cụm, không chỉ hệ thống tệp cục bộ.

## SCALABILITY AND HIGH AVAILABILITY

Trong kiến ​​trúc truyền thống, khách hàng nói chuyện với một thành phần tập trung (ví dụ:a gateway, broker, API, facade, v.v.), hoạt động như một điểm truy cập duy nhất vào một hệ thống con phức tạp. Điều này đặt ra giới hạn đối với cả hiệu suất và khả năng mở rộng, đồng thời dẫn đến một điểm lỗi duy nhất (tức là nếu thành phần tập trung gặp sự cố, thì toàn bộ hệ thống cũng đi xuống).

Ceph loại bỏ gateway tập trung để cho phép khách hàng tương tác trực tiếp với `Ceph OSD Daemons`. `Ceph OSD Daemon` tạo bản sao objects trên các Ceph Nodes khác để đảm bảo an toàn dữ liệu và tính sẵn sàng cao. Ceph cũng sử dụng một cụm monitors để đảm bảo tính khả dụng cao. Để loại bỏ sự tập trung, Ceph sử dụng một thuật toán gọi là `CRUSH`.

### 1. Giới thiệu thuật toán CRUSH
*Ceph Clients* và *Ceph OSD Daemons* đều sử dụng thuật toán `CRUSH` để tính toán hiệu quả thông tin về vị trí object, thay vì phải phụ thuộc vào bảng tra cứu trung tâm. `CRUSH` cung cấp một cơ chế quản lý dữ liệu tốt hơn so với các phương pháp tiếp cận cũ và cho phép quy mô lớn bằng cách phân phối sạch sẽ công việc cho tất cả các máy khách và daemon OSD trong cụm. `CRUSH` sử dụng nhân bản dữ liệu thông minh để đảm bảo khả năng phục hồi, phù hợp hơn với lưu trữ siêu quy mô. Các phần sau cung cấp thêm chi tiết về cách `CRUSH` hoạt động.

### 2. CLUSTER MAP
Ceph phụ thuộc vào `Ceph Clients` và `Ceph OSD Daemon` có kiến ​​thức về cấu trúc liên kết cụm, bao gồm 5 map được gọi chung là “Cluster Map”:

1. **The Monitor Map**: Chứa cluster `fsid` , vị trí, địa chỉ tên và cổng của mỗi monitor. Nó cũng cho biết Chu kỳ thời gian hiện tại, thời điểm map được tạo và lần cuối cùng nó thay đổi. Để xem , hãy thực hiện `ceph mon dump`.

2. **OSD Map**: Chứa cluster `fsid`, khi map được tạo và sửa đổi lần cuối, danh sách các nhóm, kích thước bản sao, số PG, danh sách các OSD và trạng thái của chúng (ví dụ: `up`, `in`). Để xem OSD map, hãy thực hiện `ceph osd dump`.

3. **PG Map**: Chứa PG version, time stamp, Chu kỳ thời gian OSD map cuối cùng, tỷ lệ đầy đủ và chi tiết về từng placement groups như **PG ID**, *Bộ thiết lập*, *Bộ diễn xuất*, *trạng thái* của PG (ví dụ: ,`active + clean`) và thống kê sử dụng dữ liệu cho từng nhóm.

4. **CRUSH Map**: Chứa danh sách các thiết bị lưu trữ, phân cấp miền lỗi (ví dụ: device, host, rack, row, room, v.v.) và các quy tắc để duyệt qua hệ thống phân cấp khi lưu trữ dữ liệu. Để xem CRUSH map, hãy thực thi `ceph osd getcrushmap -o {filename}`; sau đó, dịch ngược nó bằng cách thực thi `crushtool -d {comp-crushmap-filename} -o {dec-crushmap-filename}`. Bạn có thể xem map dịch ngược trong trình soạn thảo văn bản hoặc với `cat`.

5. **MDS Map**: Chứa Chu kỳ thời gian MSD map hiện tại, thời điểm map được tạo và lần cuối cùng nó thay đổi. Nó cũng chứa nhóm để lưu trữ siêu dữ liệu, danh sách các máy chủ siêu dữ liệu và các máy chủ siêu dữ liệu nào đang hoạt động. Để xem map MDS, hãy thực thi `ceph fs dump`.

Mỗi map duy trì một lịch sử lặp đi lặp lại về các thay đổi trạng thái hoạt động của nó. Ceph Monitors duy trì một bản sao chính của map cụm bao gồm các thành viên trong cụm, trạng thái, các thay đổi và tình trạng chung của Ceph Storage Cluster

### 3. HIGH AVAILABILITY MONITORS
Trước khi `Ceph Clients` có thể **đọc hoặc ghi dữ liệu**, họ phải **liên hệ** với **Ceph Monitor** để có được bản *sao mới nhất* của **Cluster map**. *Ceph Storage Cluster* có thể **hoạt động với một monitor duy nhất**; tuy nhiên, điều này dẫn đến một điểm lỗi duy nhất (tức là nếu monitor bị hỏng, Ceph Clients không thể đọc hoặc ghi dữ liệu).

Để tăng độ tin cậy và khả năng chịu lỗi, Ceph hỗ trợ một cụm monitor. Trong một cụm monitor, độ trễ và các lỗi khác có thể khiến một hoặc nhiều monitor tụt lại phía sau trạng thái hiện tại của cụm. Vì lý do này, Ceph phải có sự thống nhất giữa các phiên bản giám sát khác nhau về trạng thái của cụm. Ceph luôn sử dụng phần lớn các monitor (ví dụ: 1, 2:3, 3:5, 4:6 v.v.) và thuật toán Paxos để thiết lập sự đồng thuận giữa các monitor về trạng thái hiện tại của cụm.

Để biết chi tiết về cấu hình monitor, hãy xem Tham khảo [cấu hình monitor](https://docs.ceph.com/en/latest/rados/configuration/mon-config-ref/).
### 4. HIGH AVAILABILITY AUTHENTICATION
Để xác định người dùng và bảo vệ khỏi các cuộc tấn công trung gian, Ceph cung cấp hệ thống xác thực `cephx` để xác thực người dùng và daemon.
## DYNAMIC CLUSTER MANAGEMENT
Trong phần [SCALABILITY AND HIGH AVAILABILITY](#scalability-and-high-availability), giải thích cách Ceph sử dụng `CRUSH`, nhận biết cluster và các daemon thông minh để mở rộng quy mô và duy trì tính khả dụng cao (HA). Chìa khóa cho thiết kế của Ceph là `Ceph OSD Daemon` tự chủ động, tự phục hồi và thông minh. Hãy cùng tìm hiểu sâu hơn về cách CRUSH hoạt động để cho phép cơ sở hạ tầng lưu trữ đám mây hiện đại đặt dữ liệu, cân bằng lại cụm và tự động khôi phục sau các lỗi.
### 1. POOLS
Hệ thống lưu trữ Ceph hỗ trợ khái niệm ‘Hồ chứa’, là các phân vùng hợp lý để lưu trữ các object.


Khách hàng Ceph truy xuất Bản đồ cụm từ Màn hình Ceph và ghi các object vào nhóm. Kích thước hoặc số lượng bản sao của nhóm, quy tắc CRUSH và số lượng placement groups xác định cách Ceph sẽ đặt dữ liệu.

Hồ bơi đặt ít nhất các thông số sau:

* Ownership/Access vào Objects
* Số lượng Placement Groups, and
* The CRUSH Rule - quy tác Crush sử dụng.
### 2. MAPPING PGS TO OSDS
Mỗi pool  có một số **placement groups** -nhóm vị trí. CRUSH tự động ánh xạ PGs sang OSD. Khi Ceph Client lưu trữ các object, CRUSH sẽ ánh xạ từng object vào một placement group.

**Mapping objects** đến **placement groups** tạo ra một lớp chuyển hướng giữa **Ceph OSD Daemon** và **Ceph Client**. Ceph Storage Cluster có thể phát triển (hoặc thu nhỏ) và cân bằng lại nơi nó lưu trữ động các object.

![Imgur](https://i.imgur.com/7JBbOnW.png)

Với bản sao của cluster map và thuật toán CRUSH, máy khách có thể tính toán chính xác OSD nào sẽ sử dụng khi đọc hoặc ghi một object cụ thể.

### 3. CALCULATING PG IDS
Khi một ứng dụng Ceph Client liên kết với một Ceph Monitor, nó sẽ truy xuất bản sao mới nhất của Cluster Map. Với Cluster Map, máy khách biết về tất cả Monitor, OSD và máy chủ siêu dữ liệu trong cụm. Tuy nhiên, *nó không biết bất cứ điều gì về vị trí object*.

Vị trí object được tính toán.

Đầu vào duy nhất được khách hàng yêu cầu là ID `object` và `pool`. Thật đơn giản: Ceph lưu trữ dữ liệu trong các nhóm được đặt tên (ví dụ: “Liverpool”). Khi khách hàng muốn lưu trữ một object được đặt tên (ví dụ: “john”, “paul”, “george”, “ringo”, v.v.), nó sẽ tính toán một ***placement group*** bằng cách sử dụng ***tên object***, ***hash code***, ***số lượng PG trong pool*** và ***tên pool***. Ứng dụng Ceph Client sử dụng các bước sau để tính PG ID.

1. Máy khách nhập `tên nhóm` và `ID \`. (ví dụ: pool = “liverpool” và object-id = “john”)
1. Ceph lấy ID object và hashes nó.
3. Ceph tính toán mô-đun hashs theo số lượng PG. (ví dụ: 58) để lấy PG ID.
4. Ceph lấy pool ID được đặt cho tên pool (ví dụ: “Liverpool” = 4)
5. Ceph thêm trước pool ID vào PG ID (ví dụ: 4,58).

### 4. PEERING AND SETS
Ceph OSD Daemon kiểm tra và báo cáo lại cho Ceph Monitor.
* `peering`: quá trình đưa tất cả các OSD lưu trữ Placement Group (PG) vào thỏa thuận về trạng thái của tất cả các object (và Metadata của chúng) trong PG đó


Khi một loạt OSD chịu trách nhiệm cho placement group, thì loạt OSD đó, chúng tôi gọi chúng là Acting Set. Một Acting Set có thể đề cập đến các Daemon Ceph OSD hiện chịu trách nhiệm cho placement group hoặc các Daemon Ceph OSD chịu trách nhiệm cho một nhóm vị trí cụ thể trong một số kỷ nguyên.


Các daemon Ceph OSD là một phần của Acting Set có thể không phải lúc nào cũng `up`. Khi OSD trong Acting Set được `up`, nó là một phần của Up Set. Up set là một điểm khác biệt quan trọng, vì Ceph có thể ánh xạ lại PGs với các Daemon Ceph OSD khác khi OSD bị lỗi.


>**Ghi chú**: </br>Trong Acting Set cho PG chứa `osd.25`, `osd.32` và `osd.61`, OSD đầu tiên,` osd.25`, là Primary. Nếu OSD đó không thành công, Secondary, `osd.32`, trở thành Primary và `osd.25` sẽ bị xóa khỏi Up Set.
### 5. REBALANCING
Khi bạn thêm `Daemon Ceph OSD` vào Ceph Storage Cluster, Cluster map sẽ được cập nhật với OSD mới. Nó thay đổi vị trí object, vì nó thay đổi đầu vào cho các tính toán. Sơ đồ sau mô tả quá trình tái cân bằng (mặc dù khá thô thiển, vì nó về cơ bản ít tác động hơn với các cụm lớn) trong đó một số, nhưng không phải tất cả PG di chuyển từ các OSD hiện có (OSD 1 và OSD 2) sang OSD mới (OSD 3 ). Ngay cả khi tái cân bằng, CRUSH vẫn ổn định. Nhiều nhóm vị trí vẫn ở cấu hình ban đầu của chúng và mỗi OSD được bổ sung thêm một số dung lượng, do đó, không có đột biến tải trên OSD mới sau khi hoàn tất việc cân bằng lại.

![Imgur](https://i.imgur.com/XRaqVxS.png)
### 6. DATA CONSISTENCY
Là một phần của việc duy trì tính nhất quán và sạch sẽ của dữ liệu, Ceph OSD cũng quét các object trong các placement groups. Nghĩa là, Ceph OSD so sánh siêu dữ liệu object trong một placement groups với các bản sao của nó trong các placement groups được lưu trữ trong các OSD khác. Việc quét (thường được thực hiện hàng ngày) sẽ phát hiện ra các lỗi OSD hoặc lỗi hệ thống tệp, thường là do sự cố phần cứng. Các OSD cũng thực hiện quét sâu hơn bằng cách so sánh dữ liệu trong các object theo từng bit. Chà kỹ (theo mặc định được thực hiện hàng tuần) sẽ tìm thấy các khối bị lỗi trên ổ đĩa mà không rõ ràng trong quá trình quét nhẹ.


































